\documentclass[
	a4paper,
	oneside,
	% BCOR = 10mm,
	DIV = 12,
	fontsize = 13pt,
	headings = normal,
	numbers = endperiod,
]{scrartcl}

%%% Length calculations
\usepackage{calc}
%%%

%%% Support for color
\usepackage{xcolor}
\definecolor{lightblue}{HTML}{03A9F4}
\definecolor{red}{HTML}{F44336}
%%%

%%% Including graphics
\usepackage{graphicx}
%%%

%%% Font selection
\usepackage{fontspec}

\setromanfont{STIX Two Text}[
	Path              = {./fonts/},
	UprightFont       = {STIX2Text-Regular.otf},
	ItalicFont        = {STIX2Text-Italic.otf},
	BoldFont          = {STIX2Text-Bold.otf},
	BoldItalicFont    = {STIX2Text-BoldItalic.otf},
	SmallCapsFeatures = {LetterSpace = 8},
]

\setsansfont{IBM Plex Sans}[
	Path              = {./fonts/},
	UprightFont       = {IBMPlexSans-Regular.otf},
	ItalicFont        = {IBMPlexSans-Italic.otf},
	BoldFont          = {IBMPlexSans-Bold.otf},
	BoldItalicFont    = {IBMPlexSans-BoldItalic.otf},
	Scale = MatchUppercase,
]

\setmonofont{IBM Plex Mono}[
	Path              = {./fonts/},
	UprightFont       = {IBMPlexMono-Regular.otf},
	ItalicFont        = {IBMPlexMono-Italic.otf},
	BoldFont          = {IBMPlexMono-Bold.otf},
	BoldItalicFont    = {IBMPlexMono-BoldItalic.otf},
	Scale = MatchUppercase,
]
%%%

%%% Math typesetting
\usepackage{amsmath}

\usepackage{amsthm}
\newtheoremstyle{mythm}%
	{1\baselineskip} % Space above
	{1\baselineskip} % Space below
	{\itshape} % Body font
	{} % Indent amount
	{\upshape\bfseries} % Theorem head font
	{.} % Punctuation after theorem head
	{0.5em} % Space after theorem head
	{} % Theorem head spec
\theoremstyle{mythm}
\newtheorem{mythm}{Теорема}
\newtheorem{mydef}{Визначення}

\usepackage{IEEEtrantools}

\usepackage{unicode-math}
\setmathfont{STIX Two Math}
%%%

%%% List settings
\usepackage{enumitem}
\setlist[enumerate]{
	label*      = {\arabic*.},
	leftmargin  = *,
	labelindent = \parindent,
	topsep      = 1\baselineskip,
	parsep      = 0\baselineskip,
	itemsep     = 1\baselineskip,
}

\setlist[itemize]{
	label*      = {—},
	leftmargin  = *,
	% labelindent = \parindent,
	align       = left,
	topsep      = 1\baselineskip,
	parsep      = 0\baselineskip,
	itemsep     = 0\baselineskip,
}

\setlist[description]{
	font        = {\rmfamily\upshape\bfseries},
	topsep      = 1\baselineskip,
	parsep      = 0\baselineskip,
	itemsep     = 0\baselineskip,
}

\newlist{termpaperinfo}{enumerate}{3}
\setlist[termpaperinfo]{
	label*      = {\arabic*.},
	leftmargin  = *,
	align       = left,
	topsep      = 1\baselineskip,
	parsep      = 0\baselineskip,
	itemsep     = 1\baselineskip,
}

%%%

%%% Structural elements typesetting
\setkomafont{pagenumber}{\rmfamily\upshape}
\setkomafont{disposition}{\rmfamily\bfseries}

% Sectioning
\RedeclareSectionCommand[
	beforeskip = -1\baselineskip,
	afterskip  = 1\baselineskip,
	font       = {\normalsize\bfseries},
]{section}

% \renewcommand*{\sectionformat}{\thesection\autodot\enskip}

\renewcommand{\sectionlinesformat}[4]{%
	\centering{}#3#4%
}

\RedeclareSectionCommand[
	beforeskip = -1\baselineskip,
	afterskip  = 1\baselineskip,
	font       = {\normalsize\bfseries},
]{subsection}

\RedeclareSectionCommand[
	beforeskip = -1\baselineskip,
	afterskip  = 1\baselineskip,
	font       = {\normalsize\bfseries},
]{subsubsection}

\RedeclareSectionCommand[
	beforeskip = -1\baselineskip,
	afterskip  = -0.5em,
	font       = {\normalsize\mdseries\scshape\addfontfeatures{Letters = {UppercaseSmallCaps}}},
]{paragraph}
%%%

%%% Typographic enhancements
\usepackage{microtype}
%%%

%%% Language-specific settings
\usepackage{polyglossia}
\setmainlanguage{ukrainian}
\setotherlanguages{english}
%%%

%%% Captions
\usepackage{caption}
\usepackage{subcaption}

%\DeclareCaptionLabelFormat{closing}{#2)}
%\captionsetup[subtable]{labelformat = closing}

%\captionsetup[subfigure]{labelformat = closing}

\captionsetup[table]{
	aboveskip = 0\baselineskip,
	belowskip = 0\baselineskip,
}

\captionsetup[figure]{
	aboveskip = 1\baselineskip,
	belowskip = 0\baselineskip,
}

\captionsetup[subfigure]{
	labelformat = simple,
	labelformat = brace,
}
%%%

%%% Hyphenated ragged typesetting
\usepackage{ragged2e}
%%%

%%% Table typesetting
\usepackage{booktabs}
\usepackage{longtable}

\usepackage{multirow}

\usepackage{array}
\newcolumntype{v}[1]{>{\RaggedRight\arraybackslash\hspace{0pt}}p{#1}}
\newcolumntype{b}[1]{>{\Centering\arraybackslash\hspace{0pt}}p{#1}}
\newcolumntype{n}[1]{>{\RaggedLeft\arraybackslash\hspace{0pt}}p{#1}}
%%%

%%% Drawing
\usepackage{tikz}
\usepackage{tikzscale}
\usetikzlibrary{positioning}
\usetikzlibrary{arrows.meta} % Stealth arrow tips
%%%

%%% SI units typesetting
\usepackage{siunitx}
\sisetup{
	output-decimal-marker = {,},
	exponent-product      = {\cdot},
	inter-unit-product    = \ensuremath{{} \cdot {}},
	per-mode              = symbol,
}
%%%

%%% Framing code listings
\usepackage{tcolorbox}
\tcbuselibrary{breakable}
\tcbuselibrary{minted}
\tcbuselibrary{skins}

\newtcbinputlisting[auto counter, list inside, number within = section]{\inputpython}[4][]{%
	minted language = python,
	minted style    = bw,
	minted options  = {
		linenos,
		tabsize = 4,
		breaklines,
		breakbytokenanywhere,
		fontsize = \footnotesize,
	},
	%
	% empty,
	sharp corners,
	colframe         = black,
	colback          = black!0,
	leftrule         = 0em,
	rightrule        = 0em,
	toprule          = 0pt, % orig = 0pt
	bottomrule       = 0pt, % orig = 0pt
	titlerule        = 0.5pt,
	colbacktitle     = black!0,
	coltitle         = black,
	toptitle         = 0.3em,
	bottomtitle      = 0.1em,
	borderline north = {1pt}{0pt}{black},
	borderline south = {1pt}{0pt}{black},
	before skip      = \intextsep,
	after  skip      = \intextsep,
	title            = {Лістинг \thetcbcounter: #3},
	list entry       = {\protect\numberline{\thetcbcounter}#3},
	left = 0em,
	right = 0em,
	%
	listing file={#2},
	listing only,
	breakable,
	%
	label = {#4},
	%
	#1
}

% Customize minted line numbers
\renewcommand{\theFancyVerbLine}{\ttfamily\scriptsize\arabic{FancyVerbLine}}

%%%

%%% Bibliography
\usepackage[
	style    = gost-numeric,
	language = auto,
	autolang = other,
	sorting  = none,
]{biblatex}
\addbibresource{y03s01-syssoft-term-paper-01-bibliography.bib}
%%%

%%% Links and hyperreferences
\usepackage{hyperref}
\hypersetup{
	bookmarksnumbered = true,
	colorlinks      = false,
	linkbordercolor = red,
	urlbordercolor  = lightblue,
	pdfborderstyle  = {/S/U/W 1.5},
}
%%%

%%% Length adjustments
% Set baselineskip, default is 14.5 pt
\linespread{1.068966} % ~15.5 pt
\setlength{\emergencystretch}{1em}
\setlength{\parindent}{1.5em}
\newlength{\gridunitwidth}
\setlength{\gridunitwidth}{\textwidth / 12}
%%%

%%% Custom commands
\newcommand{\blankspace}[1]{\underline{\hspace{#1}}}
\newcommand{\allcaps}[1]{{\addfontfeatures{LetterSpace = 8, Kerning = Off}#1}}
\newcommand{\filename}[1]{\texttt{#1}}
\newcommand{\progname}[1]{\texttt{#1}}

\newcommand{\myvec}[1]{\mathbf{#1}}
%%%

\begin{document}

\begin{titlepage}
		\begin{center}
			Міністерство освіти і науки України\\
			Національний авіаційний університет\\
			Навчально-науковий інститут комп'ютерних інформаційних технологій\\
			Кафедра комп'ютеризованих систем управління

			\vspace{\fill}
				Курсова робота\\
				з дисципліни «Системне програмне забезпечення»\\

				\vspace*{3\baselineskip}

				Пояснювальна записка\\
				Тема: реалізація наївного баєсового класифікатора на~мові~програмування~\textenglish{Python}

			\vspace{\fill}

			\begin{flushright}
				Виконав:\\
				студент групи СП-325\\
				Клокун В.\,Д.\\
			\end{flushright}

			Київ — 2018
		\end{center}
	\end{titlepage}

	\section*{Завдання на~виконання курсової~роботи\\студента групи~СП-325 Клокуна Владислава~Денисовича}
	% {\centering{}студента групи~СП-325 Клокуна Владислава Денисовича\par}
	\begin{termpaperinfo}
		\item Тема курсової роботи: реалізація наївного баєсового класифікатора на~мові~програмування~\textenglish{Python} для класифікації спостережень, що~містять неперервні дані.
		\item Термін виконання курсової роботи:\\ з~«\blankspace{1cm}» \blankspace{4cm}~2018~р. по~«\blankspace{1cm}»~\blankspace{4cm}~2018~р.
		\item Вхідні дані до роботи: набір даних для класифікації.
		\item Етапи виконання курсової роботи:
			\begin{itemize}
				\item Огляд теоретичних відомостей про наївний баєсов класифікатор.
				\item Реалізація та тестування наївного баєсового класифікатора.
			\end{itemize}
		\item Перелік обов'язкових додатків і графічного матеріалу:
			\begin{itemize}
				\item FIXME.
			\end{itemize}
	\end{termpaperinfo}

	{%
		\newlength{\blanklinematch}
		\setlength{\blanklinematch}{1cm + \widthof{» } + 5cm}
		\noindent%
		\begin{tabular}{
				@{}ll
			}
			Завдання отримав: & «\blankspace{1cm}» \blankspace{5cm}~2018~р.\\
			Підпис студента:  & \phantom{«}\blankspace{\blanklinematch}~(Клокун В.\,Д.)\\
			% Підпис студента:  & \blankspace{\widthof{«} + 1cm + \widthof{»} + 5cm}~(Клокун В.\,Д.)
		\end{tabular}
		\par
	}

	\newpage
	\tableofcontents

	\newpage
	\section{Теоретична частина}
		\subsection{Короткі теоретичні відомості}
			\label{ssec:theory-short}
			Припустимо, що~в~ході деякого експерименту проводились спостереження, під час проведення яких збирались неперервні (недискретні) дані про~результат події. Також були визначені категорії (або класи), до~яких ці~дані можуть належати. Поставлена задача класифікувати дані спостережень. \emph{Класифікація}~— це~задача визначення, до~якої з~категорій належить певне спостереження~\cite{wiki-stat-classification}. \emph{Класифікатор}~— це~алгоритм, який виконує класифікацію~\cite{wiki-stat-classification}.

			\emph{Наївний баєсів класифікатор}~— це ймовірнісний класифікатор, який використовує теорему Баєса для класифікації спостережень. Такі класифікатори отримують на вхід спостереження, оцінюють його і~роблять припущення про~клас, до~якого воно~належить. Вхідні дані, тобто спостереження, представляються у~вигляді вектора відомих значень випадкових змінних, які називаються \emph{ознаками}. Результатом роботи класифікатора є~певне значення цільової змінної або змінних, які зазвичай називаються класовими, і позначають клас, до~якого належить спостереження.

			Принцип класифікації полягає в~обчисленні умовних імовірностей~(визначення~\ref{def:conditional-probability}) того, що~вхідні дані належать до~кожного з~класів~(події, які~нас цікавлять), за~умови, що~ознаки мають певні значення~(події, які ми спостерігаємо). Після обчислення кожної з~умовних імовірностей знаходиться найбільша та~робиться висновок про~належність спостереження до~кожного з~класів. Саме тому наївний баєсів класифікатор називають~ймовірнісним.

			\begin{mydef}[Умовна ймовірність]
				\label{def:conditional-probability}
				Нехай~$A$ і~$B$~— події. Позначимо ймовірність настання кожної з~них незалежно одна від~одної як~$P(A)$ і~$P(B)$ відповідно. Тоді \emph{умовною імовірністю}~$P(A \mid B)$ називається ймовірність настання події~$A$ за~умови, що~подія~$B$ настала.
			\end{mydef}
			
			Наприклад, нехай подія~$A$~— дане спостереження належить до~певного класу, подія~$B$~— ознаки спостереження мають певні значення. Тоді щоб знайти ймовірність, що дане спостереження з~певним значенням ознак належить до~певного класу, необхідно обчислити умовну ймовірність~$P(A \mid B)$. Для~обчислення цієї імовірності необхідно використати теорему~Баєса~(теорема~\ref{thm:theorem-bayes}).

			\begin{mythm}[Баєса]
				\label{thm:theorem-bayes}
				Нехай~$P(A \mid B)$~— умовна ймовірність настання події~$A$ за~умови, що~подія~$B$ настала; $P(B \mid A)$~— умовна ймовірність настання події~$B$ за~умови, що~подія~$A$ настала і~$P(B)$~— імовірність настання події~$B$, причому~$P(B) \neq 0$. Тоді умовна ймовірність~$P(A \mid B)$ обчислюється так:
				\[
					P(A \mid B) = \frac{P(B \mid A) \, P(A)}{P(B)}.
				\]
			\end{mythm}

			Оскільки при обчисленні умовних імовірностей використовується теорема Баєса, такий імовірнісний класифікатор називається баєсовим.

		\subsection{Імовірнісна модель наївного баєсового класифікатора}
			Як було сказано у~підрозділі~\ref{ssec:theory-short}, для~виконання класифікації необхідні такі дані: вхідні дані, тобто спостереження, та~можливі значення класової змінної для позначення класів, до~яких можуть належати ці~дані. Позначатимемо змінні, на кшталт~$X_i$, великими літерами, а їх значення, наприклад, $x_i$~— малими. Вектори, на зразок~$\myvec{X}$~— жирним шрифтом.
			
			Вхідними даними для~класифікації буде вектор ознак~$\myvec{X} = \left( X_1, \dots, X_n \right)$, де~$X_1, \dots, X_n$~— ознаки. Кожна ознака може мати значення зі~своєї області визначення, яка позначається~$D_i$. Набір усіх векторів ознак позначається як~$\Omega = D_1 \times \dots \times D_n$. Для позначення класу, до якого належить спостереження, введемо випадкову змінну~$C$, де~$C$ може приймати одне з~$m$ значень: $c \in \{ 0, \dots, m - 1\}$. 

			\begin{mydef}[Розподіл імовірностей]
				Нехай~$X$ і~$Y$~— випадкові змінні, які приймають значення~$x$ та~$y$ відповідно. Тоді розподіл імовірностей~$p(X \mid Y)$ позначає значення імовірностей~$P(X = x_i \mid Y = y_i)$ для кожної з можливих пар~$i, j$.~\cite{russel-norvig-ai-ma}
			\end{mydef}

			Класифікація за допомогою наївного баєсового класифікатора ставить у~відповідність кожному вектору~$\myvec{X}$, який~містить ознаки~$X_1, \dots, X_n$, розподіли ймовірностей:
			\begin{equation}
				p\left( C \mid \myvec{X} \right) = p\left( C \mid X_1, \dots, X_n \right).
			\end{equation}
			Зі~зростанням кількості або~можливих значень ознак, з~такою моделлю неможливо працювати за~допомогою таблиць імовірностей, тому~переформулюємо модель, щоб~зробити її зручнішою.

			Використовуючи теорему Баєса, представимо її так:
			\begin{equation}
				p(C \mid X_1, \dots, X_n) = \frac{p(C) \, p(X_1, \dots, X_n \mid C)}{p( X_1, \dots, X_n)}.
			\end{equation}
			Видно, що~дільник не~залежить від~змінної~$C$, а~значення ознак~$X_i$ задані наперед, тому на~практиці значення дільника постійне. Ділене рівносильне такій моделі спільного розподілу:
			\begin{equation}
				p(C, X_1, \dots, X_n).
			\end{equation}
			Перетворюємо дану модель за~допомогою визначення умовної ймовірності:
			\begin{IEEEeqnarray*}{rCl}
				p(C, X_1, \dots, X_n) &=& p(C) \, p(X_1, \dots, X_n \mid C)\\
				                      &=& p(C) \, p(X_1 \mid C) \, p(X_2, \dots, X_n \mid C, X_1)\\
															&=& p(C) \, p(X_1 \mid C) \, p(X_2 \mid C, X_1) \, p(X_3, \dots, X_n \mid C, X_1, X_2)\\
															&=& p(C) \, p(X_1 \mid C) \, p(X_2 \mid C, X_1) \, p(X_3 \mid C, X_1, X_2) \, p(X_4, \dots, X_n \mid C, X_1, X_2, X_3)
			\end{IEEEeqnarray*}
			і~так далі. Тепер припускаємо, що кожна ознака~$X_i$ умовно незалежна від~кожної іншої ознаки~$X_j$, для будь-яких~$j \neq i$ та~заданої категорії~$C = c$. Математично це означає:
			\begin{IEEEeqnarray*}{rCl}
				p (X_i \mid C, X_j) = p (X_i \mid C).
			\end{IEEEeqnarray*}
			Таке припущення є наївним, оскільки немає жодних підстав вважати, що вхідні ознаки дійсно незалежні одна від одної. Саме тому такий баєсовий класифікатор називається наївним.

			% \begin{IEEEeqnarray*}{rCl}
			% 	p(C, X_1, \dots, X_n) &=& p( X_1, \dots, X_n, C) \\
			% 												&=& p( X_1 \mid X_2, \dots, X_n, C) \, p(X_2, \dots, X_n, C) \\
			% 												&=& p( X_1 \mid X_2, \dots, X_n, C) \, p( X_2 \mid X_3, \dots, X_n, C) \, p(X_3, \dots, X_n, C) \\
			% 												&\dots& \\
			% 												&=& p( X_1 \mid X_2, \dots, X_n, C) \, p( X_2 \mid X_3, \dots, X_n, C) \dots p(X_{n-1} \mid X_n, C) \, p(X_n | C) \, p(C). \\
			% \end{IEEEeqnarray*}

			Отже, виражаємо загальну модель:
			\begin{IEEEeqnarray}{rCl}
				p(C \mid X_1, \dots, X_n) &=& p(C) \, p(X_1 \mid C) \, p(X_2 \mid C) \dots p(X_n \mid C) \\
																	&=& p(C) \prod_{i=1}^{n} p(X_i \mid C).
			\end{IEEEeqnarray}
			Це означає, що враховуючи припущення про незалежність змінних, умовний розподіл над класовою змінною~$C$ може бути виражений так:
			\begin{IEEEeqnarray}{rCl}
				p(C \mid X_1, \dots, X_n) = \frac{1}{Z} \, p(C) \prod_{i=1}^{n} p( X_i \mid C),
			\end{IEEEeqnarray}
			де~$Z$~— коефіцієнт,~який залежить виключно від~$X_1, \dots, X_n$. Якщо~значення ознак~$x_1, \dots, x_n$ відомі, коефіцієнт~$Z$ сталий.

			Таку модель значно зручніше використовувати, оскільки вони використовують апріорні імовірності класів~$p(C)$ та незалежні розподіли~$p(X_i \mid C)$. Якщо є~$k$~класів та модель модель для~$p(X_i)$ може бути виражена $r$~ параметрами, то відповідний наївний баєсовий класифікатор матиме~$(k - 1) + nrk$ параметрів.~\cite{murty-devy-pattern-rec}

		\subsection{Оцінка параметрів}
			Описавши ймовірнісну модель, необхідно визначити її параметри, тобто апріорні ймовірності належності до~класу~$p(C)$ та~розподіли ймовірностей ознак~$p(X_i \mid C)$. Для обчислення параметрів моделі використовують \emph{тренувальний набір даних}~— такий набір даних, який складається із заздалегідь класифікованих спостережень. Тобто набір даних~$S$ складатиметься з~векторів~$\myvec{x} = (x_1, \dots, x_n, c)$, де~$c$~— правильне значення класової змінної.
			
			Усі параметри моделі можна обчислити з~тренувального набору даних.~\cite{murty-devy-pattern-rec} Щоб оцінити значення параметрів, необхідно зробити припущення щодо розподілу, який характеризує дані. Припущення щодо розподілу, який характеризує дані, називають \emph{моделлю подій}. При роботі з~неперервними (недискретними) даними, зазвичай припускають, що~вони розподілені за~законом нормального (гаусового) розподілу. Нормальний розподіл характеризується двома величинами: математичним сподіванням~$\mu$ та~дисперсією випадкової величини~$\sigma^2$. 

			Наприклад, припустимо, що тренувальний набір даних містить неперервну ознаку~$X$. Щоб обчислити розподіл імовірності, необхідно спочатку розподілити дані за класами, наданими у тренувальному наборі, та обчислити математичне сподівання $\mu_{c}$ і дисперсію випадкової величини~$\sigma_{c}^{2}$.

			Нехай необхідно обчислити ймовірність, що  

	\newpage
	\section{Практична частина}

	\newpage
	\addsec{Висновки}

	\newpage
	\printbibliography

\end{document}
